{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeedTest_CPU_v_GPU_Colab_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNNBOiDhyXLnbabPTYQ/roq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdhauswirth/colab_public/blob/main/SpeedTest_CPU_v_GPU_Colab_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CPU vs GPU - Processing Speed Test using TensorFlow\n",
        "This notebook creates random image data and uses a CNN to compare processing speed between CPU and GPU using Google Colab.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Author**: [Joel Hauswirth](https://eportfolio.mygreatlearning.com/joel-d-hauswirth)   \n",
        "##### **Date**:         2022/01/15   \n",
        "##### **Last Updated**: 2022/01/16\n"
      ],
      "metadata": {
        "id": "gQgJ8qP3RIYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### **Credit to**: [J. Curtis](https://www.linkedin.com/in/jacob-dee-curtis) (Great Learning Mentor) and [Great Learning](https://olympus1.mygreatlearning.com/r/1933826/679) for the original code that inspired this notebook during one of our lessons during NN (Neural Networks) prework course of [UT AIML PGP Program](https://utaustin.mygreatlearning.com/artificial-intelligence-machine-learning-course?&utm_source=Google&utm_medium=search&utm_campaign=AIML_Int_Brand_BMM_US&adgroup_id=110623715467&campaign_id=10937804381&Keyword=%2But%20%2Baiml&placement=&gclid=CjwKCAiA_omPBhBBEiwAcg7smS4kom2jzg-LOdWPjnmHebOau_zToC7gAfCRU8AStS_4nt2iPmcOfhoCqn4QAvD_BwE)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "QdsluYuxROvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## License\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2022 JDHaus\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ],
      "metadata": {
        "id": "XfYWa--8JLHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "UWrtmtpFJnzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SxVfU7GQ-2d",
        "outputId": "6932cdcd-5d56-4d1a-ba17-6625ac5c13d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.7.0 loaded\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"TensorFlow version:\", tf.__version__, 'loaded')\n",
        "except ImportError:\n",
        "    !pip install tensorflow\n",
        "\n",
        "# Additional libraries\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Determine Current Device Type"
      ],
      "metadata": {
        "id": "R-fukoUiL0xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch device type \n",
        "device_type = tf.test.gpu_device_name()\n",
        "device_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "m-C3B9l-MUX0",
        "outputId": "f67a0322-05f1-4b57-acb5-938e325d4286"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check device type\n",
        "if device_type != '/device:GPU:0':\n",
        "    print(\n",
        "        '\\n\\nThis error most likely means this notebook is not '\n",
        "        'setup to use a GPU.\\nChange this in Notebook Settings via '\n",
        "        'command palette by entering\\n(cmd/ctrl-shift-P and type \"Open '\n",
        "        'notebook settings\")\\nor via the Google Colab Edit menu -> '\n",
        "        'Notebook settings.\\n\\n'\n",
        "        )\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "id": "GRuIvATAMNdC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data & Define Functions"
      ],
      "metadata": {
        "id": "7BtNDEu4Pd8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random image parameters \n",
        "input_shape = (101, 100, 100, 3) # (Batch size, 100x100, 3 RGB Channels)\n",
        "\n",
        "# Set convolution window parameters \n",
        "filters = 32     # filters = number of neurons\n",
        "kernel_size = 7  # int or tuple/list 2 ints, HxW of 2D convolution window\n",
        "\n",
        "# Define Function CPU\n",
        "def cpu():\n",
        "    '''\n",
        "    A function to generate random image data using a CPU (Central Processing Unit).\n",
        "    '''\n",
        "    with tf.device('/device:cpu:0'):\n",
        "      random_image_cpu = tf.random.normal((input_shape))\n",
        "      net_cpu = tf.keras.layers.Conv2D(filters, kernel_size)(random_image_cpu)\n",
        "      return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "# Define Function GPU\n",
        "def gpu():\n",
        "    '''\n",
        "    A function to generate random image data using a GPU (Graphics Processing Unit).\n",
        "    '''\n",
        "    with tf.device('/device:GPU:0'):\n",
        "      random_image_gpu = tf.random.normal((input_shape))\n",
        "      net_gpu = tf.keras.layers.Conv2D(filters, kernel_size)(random_image_gpu)\n",
        "      return tf.math.reduce_sum(net_gpu)"
      ],
      "metadata": {
        "id": "2DCT0H4gRNaI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run each function/operation once to \"warm up\", then run a 2nd time."
      ],
      "metadata": {
        "id": "Y3t1x3XJyJjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_time1 = timeit.timeit('cpu()', number = 1, setup = 'from __main__ import cpu')\n",
        "print(f'{cpu_time1:.4f} seconds for 1st CPU cycle')\n",
        "\n",
        "cpu_time2 = timeit.timeit('cpu()', number = 1, setup = 'from __main__ import cpu')\n",
        "print(f'{cpu_time2:.4f} seconds for 2nd CPU cycle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxljrh3Vxe1v",
        "outputId": "b4975de3-0edd-4074-845c-533aa9d4e652"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7231 seconds for 1st CPU cycle\n",
            "0.5154 seconds for 2nd CPU cycle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_time1 = timeit.timeit('gpu()', number = 1, setup = 'from __main__ import gpu')\n",
        "print(f'{gpu_time1:.4f} seconds for 1st GPU cycle')\n",
        "\n",
        "gpu_time2 = timeit.timeit('gpu()', number = 1, setup = 'from __main__ import gpu')\n",
        "print(f'{gpu_time2:.4f} seconds for 2nd GPU cycle')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUBCIFlGxe5t",
        "outputId": "0fa98e99-688e-45bb-fc01-0c427e263606"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8290 seconds for 1st GPU cycle\n",
            "0.0058 seconds for 2nd GPU cycle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare results of warm up times"
      ],
      "metadata": {
        "id": "rWJ8EG6C2N3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_time1 / cpu_time2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOJ11Rec2hRO",
        "outputId": "0939014e-877b-4b61-9bd9-c27767ea98da"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4030649735405984"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_time2 / cpu_time1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUhIwX_q2MNs",
        "outputId": "0ee1f802-655e-4bfe-872a-6821a4a8200a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7127253682889151"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_time1 / gpu_time2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JixP6Q9e2hT0",
        "outputId": "36cb2496-e839-4225-9515-9ceeeb173170"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "313.4763787725907"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_time2 / gpu_time1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHcJsEgd2MbT",
        "outputId": "74b7858d-2503-4d0a-8016-6b50093a1ec9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0031900330223140773"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Take a moment to think about why the times would differ.  (Or reference [Stack Overflow](https://stackoverflow.com/questions/45063489) issue) \n",
        "\n",
        "### Perform speed test & compare results "
      ],
      "metadata": {
        "id": "Hn8SVg_I9bK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of cycles to run the operation\n",
        "n_cycles = 10"
      ],
      "metadata": {
        "id": "HaGbJX6n9se6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run CPU operation n times\n",
        "cpu_time_n = timeit.timeit('cpu()', number = n_cycles, setup = 'from __main__ import cpu')\n",
        "print(f'CPU Processing Time: {cpu_time_n:.3f} seconds')\n",
        "\n",
        "# Run GPU operation n times\n",
        "gpu_time_n = timeit.timeit('gpu()', number = n_cycles, setup = 'from __main__ import gpu')\n",
        "print(f'GPU Processing Time: {gpu_time_n:.3f} seconds')\n",
        "\n",
        "# Calculate and dsiplay results\n",
        "print(f'GPU Speed Increase:  {(int(cpu_time_n/gpu_time_n)):.0f}X faster than the CPU\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0BI8F00TL_r",
        "outputId": "c25cf93f-9d2e-418e-de14-c6e11b3a9f05"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Processing Time: 5.743 seconds\n",
            "GPU Processing Time: 0.064 seconds\n",
            "GPU Speed Increase:  89X faster than the CPU\n",
            "\n"
          ]
        }
      ]
    }
  ]
}